{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2eb6a96-5bdf-4144-9305-16962bff807f",
   "metadata": {},
   "source": [
    "Pré-processamento e filtragem de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52b8e90a-d919-4116-b000-4faf88095570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensão do DataFrame filtrado e pré-processado: (20285, 7)\n",
      "Arquivos Parquet de dados brutos de prod e dev criados com sucesso.\n",
      "Dimensões do conjunto de treino: (16228, 6) (16228,)\n",
      "Dimensões do conjunto de teste: (4057, 6) (4057,)\n",
      "Conjuntos de dados salvos com sucesso e parâmetros registrados no Mlflow.\n"
     ]
    }
   ],
   "source": [
    "# Importar Bibliotecas Necessárias\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import mlflow\n",
    "\n",
    "# Definir o local onde o MLflow irá armazenar os resultados\n",
    "mlflow.set_tracking_uri(\"file:///C:/Users/andre/Proj_Kobe-Bryant-Shot-Selection/data/modeling/tracking/mlruns\")\n",
    "\n",
    "mlflow.set_experiment(\"PreparacaoDados\")\n",
    "\n",
    "# Definir a função para pré-processamento de dados\n",
    "def preprocess_data(raw_data_file):\n",
    "    \"\"\"\n",
    "    Função para pré-processamento e filtragem de dados.\n",
    "    \n",
    "    Args:\n",
    "    - raw_data_file (str): Caminho do arquivo CSV contendo os dados brutos.\n",
    "    \n",
    "    Returns:\n",
    "    - processed_data (DataFrame): DataFrame pré-processado e filtrado.\n",
    "    \"\"\"\n",
    "    # Carregar os dados brutos do arquivo CSV\n",
    "    df_raw = pd.read_csv(raw_data_file, sep=',')\n",
    "    \n",
    "    # Filtrar os dados onde o valor de shot_type é igual a '2PT Field Goal'\n",
    "    df_filtered = df_raw[df_raw['shot_type'] == '2PT Field Goal']\n",
    "\n",
    "    # Filtrar o DataFrame para incluir apenas as colunas especificadas\n",
    "    columns_to_keep = ['lat', 'lon', 'minutes_remaining', 'period', 'playoffs', 'shot_distance', 'shot_made_flag']\n",
    "    processed_data = df_filtered[columns_to_keep].copy()\n",
    "\n",
    "    # Tratar dados ausentes, se houver\n",
    "    processed_data.dropna(inplace=True)\n",
    "\n",
    "    # Substituir valores faltantes na coluna 'shot_made_flag' por 0 (indicando que o arremesso foi errado)\n",
    "    processed_data['shot_made_flag'] = processed_data['shot_made_flag'].astype(int)\n",
    "\n",
    "    return processed_data\n",
    "\n",
    "# Inicie uma rodada do MLflow\n",
    "with mlflow.start_run(run_name=\"PreparacaoDados\"):\n",
    "    \n",
    "    # Caminho do arquivo CSV contendo os dados brutos\n",
    "    raw_data_file = \"C:/Users/andre/Proj_Kobe-Bryant-Shot-Selection/data/raw/data.csv\"\n",
    "    \n",
    "    # Executar a função de pré-processamento de dados\n",
    "    df_kobe = preprocess_data(raw_data_file)\n",
    "    \n",
    "    # Exibir as primeiras linhas do DataFrame pré-processado\n",
    "    print(\"Dimensão do DataFrame filtrado e pré-processado:\", df_kobe.shape)\n",
    "    df_kobe.head()\n",
    "    \n",
    "    # Salvar o DataFrame pré-processado em arquivos Parquet de desenvolvimento e produção\n",
    "    output_file_dev = \"C:/Users/andre/Proj_Kobe-Bryant-Shot-Selection/data/raw/dataset_kobe_dev.parquet\"\n",
    "    output_file_prod = \"C:/Users/andre/Proj_Kobe-Bryant-Shot-Selection/data/raw/dataset_kobe_prod.parquet\"\n",
    "    df_kobe.to_parquet(output_file_dev)\n",
    "    df_kobe.to_parquet(output_file_prod)\n",
    "    \n",
    "    # Log dos arquivos de dados processados como artefatos no MLflow\n",
    "    mlflow.log_artifact(output_file_dev)\n",
    "    mlflow.log_artifact(output_file_prod)\n",
    "\n",
    "    print(\"Arquivos Parquet de dados brutos de prod e dev criados com sucesso.\")\n",
    "    \n",
    "    # Calcular dimensão do dataset resultante\n",
    "    df_dimension = df_kobe.shape[0]\n",
    "    \n",
    "    # Log da dimensão do dataset resultante\n",
    "    mlflow.log_param(\"dimensao_dataset\", df_dimension)\n",
    "\n",
    "#Divisão dos Dados em Conjuntos de Treino (80%) e Teste (20 %)\n",
    "def split_data(data, test_size=0.2):\n",
    "\n",
    "    X = data.drop('shot_made_flag', axis=1)\n",
    "    y = data['shot_made_flag']\n",
    "    \n",
    "    # Dividir os dados de forma aleatória e estratificada\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, stratify=y, random_state=42)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "# Dividir os dados em conjuntos de treino e teste\n",
    "X_train, X_test, y_train, y_test = split_data(df_kobe)\n",
    "\n",
    "# Exibir informações sobre a divisão\n",
    "print(\"Dimensões do conjunto de treino:\", X_train.shape, y_train.shape)\n",
    "print(\"Dimensões do conjunto de teste:\", X_test.shape, y_test.shape)\n",
    "\n",
    "# Armazenar os datasets resultantes em arquivos Parquet\n",
    "def save_data(X, y, file_path):\n",
    "\n",
    "    # Criar o diretório se não existir\n",
    "    os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
    "    \n",
    "    # Concatenar os recursos e o alvo\n",
    "    data = pd.concat([X, y], axis=1)\n",
    "    \n",
    "    # Salvar os dados em formato Parquet\n",
    "    data.to_parquet(file_path, index=False)\n",
    "\n",
    "# Salvar os conjuntos de dados em arquivos Parquet\n",
    "save_data(X_train, y_train, \"C:/Users/andre/Proj_Kobe-Bryant-Shot-Selection/data/processed/base_train.parquet\")\n",
    "save_data(X_test, y_test, \"C:/Users/andre/Proj_Kobe-Bryant-Shot-Selection/data/processed/base_test.parquet\")\n",
    "\n",
    "# Log dos parâmetros\n",
    "mlflow.log_param(\"percentual_teste\", 0.2)\n",
    "\n",
    "# Log das métricas\n",
    "mlflow.log_metric(\"tamanho_base_treino\", X_train.shape[0])\n",
    "mlflow.log_metric(\"tamanho_base_teste\", X_test.shape[0])\n",
    "\n",
    "print(\"Conjuntos de dados salvos com sucesso e parâmetros registrados no Mlflow.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
