{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2eb6a96-5bdf-4144-9305-16962bff807f",
   "metadata": {},
   "source": [
    "Pré-processamento e filtragem de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "52b8e90a-d919-4116-b000-4faf88095570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensão do DataFrame filtrado e pré-processado: (20285, 7)\n",
      "Arquivos Parquet de dados brutos de prod e dev criados com sucesso.\n"
     ]
    }
   ],
   "source": [
    "# Importar Bibliotecas Necessárias\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Definir a função para pré-processamento de dados\n",
    "def preprocess_data(raw_data_file):\n",
    "    \"\"\"\n",
    "    Função para pré-processamento e filtragem de dados.\n",
    "    \n",
    "    Args:\n",
    "    - raw_data_file (str): Caminho do arquivo CSV contendo os dados brutos.\n",
    "    \n",
    "    Returns:\n",
    "    - processed_data (DataFrame): DataFrame pré-processado e filtrado.\n",
    "    \"\"\"\n",
    "    # Carregar os dados brutos do arquivo CSV\n",
    "    df_raw = pd.read_csv(raw_data_file, sep=',')\n",
    "    \n",
    "    # Filtrar os dados onde o valor de shot_type é igual a '2PT Field Goal'\n",
    "    df_filtered = df_raw[df_raw['shot_type'] == '2PT Field Goal']\n",
    "\n",
    "    # Filtrar o DataFrame para incluir apenas as colunas especificadas\n",
    "    columns_to_keep = ['lat', 'lon', 'minutes_remaining', 'period', 'playoffs', 'shot_distance', 'shot_made_flag']\n",
    "    processed_data = df_filtered[columns_to_keep].copy()\n",
    "\n",
    "    # Tratar dados ausentes, se houver\n",
    "    processed_data.dropna(inplace=True)\n",
    "\n",
    "    # Substituir valores faltantes na coluna 'shot_made_flag' por 0 (indicando que o arremesso foi errado)\n",
    "    processed_data['shot_made_flag'] = processed_data['shot_made_flag'].astype(int)\n",
    "\n",
    "    return processed_data\n",
    "\n",
    "# Caminho do arquivo CSV contendo os dados brutos\n",
    "raw_data_file = 'Proj_Kobe-Bryant-Shot-Selection/data/raw/data.csv'\n",
    "\n",
    "# Executar a função de pré-processamento de dados\n",
    "df_kobe = preprocess_data(raw_data_file)\n",
    "\n",
    "# Exibir as primeiras linhas do DataFrame pré-processado\n",
    "print(\"Dimensão do DataFrame filtrado e pré-processado:\", df_kobe.shape)\n",
    "df_kobe.head()\n",
    "\n",
    "# Salvar o DataFrame pré-processado em arquivos Parquet de desenvolvimento e produção\n",
    "output_file_dev = 'Proj_Kobe-Bryant-Shot-Selection/data/processed/dataset_kobe_dev.parquet'\n",
    "output_file_prod = 'Proj_Kobe-Bryant-Shot-Selection/data/processed/dataset_kobe_prod.parquet'\n",
    "df_kobe.to_parquet(output_file_dev)\n",
    "df_kobe.to_parquet(output_file_prod)\n",
    "\n",
    "print(\"Arquivos Parquet de dados brutos de prod e dev criados com sucesso.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eca05ac-1b4c-4b34-958e-60bb92f6a044",
   "metadata": {},
   "source": [
    "Divisão dos Dados em Conjuntos de Treino (80%) e Teste (20 %)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2f157d61-80f7-4227-a1bc-a3827827de18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensões do conjunto de treino: (16228, 6) (16228,)\n",
      "Dimensões do conjunto de teste: (4057, 6) (4057,)\n",
      "Conjuntos de dados salvos com sucesso.\n"
     ]
    }
   ],
   "source": [
    "def split_data(data, test_size=0.2):\n",
    "\n",
    "    X = data.drop('shot_made_flag', axis=1)\n",
    "    y = data['shot_made_flag']\n",
    "    \n",
    "    # Dividir os dados de forma aleatória e estratificada\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, stratify=y, random_state=42)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "# Dividir os dados em conjuntos de treino e teste\n",
    "X_train, X_test, y_train, y_test = split_data(df_kobe)\n",
    "\n",
    "# Exibir informações sobre a divisão\n",
    "print(\"Dimensões do conjunto de treino:\", X_train.shape, y_train.shape)\n",
    "print(\"Dimensões do conjunto de teste:\", X_test.shape, y_test.shape)\n",
    "\n",
    "# Armazenar os datasets resultantes em arquivos Parquet\n",
    "def save_data(X, y, file_path):\n",
    "\n",
    "    # Criar o diretório se não existir\n",
    "    os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
    "    \n",
    "    # Concatenar os recursos e o alvo\n",
    "    data = pd.concat([X, y], axis=1)\n",
    "    \n",
    "    # Salvar os dados em formato Parquet\n",
    "    data.to_parquet(file_path, index=False)\n",
    "\n",
    "# Salvar os conjuntos de dados em arquivos Parquet\n",
    "save_data(X_train, y_train, \"Proj_Kobe-Bryant-Shot-Selection/data/processed/base_train.parquet\")\n",
    "save_data(X_test, y_test, \"Proj_Kobe-Bryant-Shot-Selection/data/processed/base_test.parquet\")\n",
    "\n",
    "print(\"Conjuntos de dados salvos com sucesso.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500a9bfd-3802-482f-bb7f-5a6470588f20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda-panel-2023.05-py310",
   "language": "python",
   "name": "conda-env-anaconda-panel-2023.05-py310-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
